---
title: "Lake Water Quality Analysis"
author: "Mary Dixon"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---



```{r setup, include=FALSE}
library(tidyverse) # Tidy packages
library(sf) #Spatial package that can read and create shapefiles 
library(mapview) #Interactive maps
library(LAGOSNE) #Lots and lots of clean lake data
library(USAboundaries) #USA states and counties
library(lubridate) #For dealing with date and time
```


# LAGOS Analysis


## Loading in data


### First download and then specifically grab the locus (or site lat longs)
```{r data-read, warning = F, message = F}
#Lagos download script
#lagosne_get(dest_folder = LAGOSNE:::lagos_path(),overwrite=T)

#Load in lagos
lagos <- lagosne_load()

#Grab the lake centroid info
lake_centers <- lagos$locus

# Make an sf object 
spatial_lakes <- st_as_sf(lake_centers,coords=c('nhd_long','nhd_lat'),
                          crs=4326)
#Grab the water quality data
nutr <- lagos$epi_nutr

#Look at column names
#names(nutr)
```

### Subset columns nutr to only keep key info that we want


```{r}
clarity_only <- nutr %>%
  select(lagoslakeid,sampledate,chla,doc,secchi) %>%
  mutate(sampledate = as.character(sampledate) %>% ymd(.))
```


### Keep sites with at least 200 observations 

```{r}
#Look at the number of rows of dataset
#nrow(clarity_only)

chla_secchi <- clarity_only %>%
  filter(!is.na(chla),
         !is.na(secchi))

# How many observatiosn did we lose?
# nrow(clarity_only) - nrow(chla_secchi)

# Keep only the lakes with at least 200 observations of secchi and chla
chla_secchi_200 <- chla_secchi %>%
  group_by(lagoslakeid) %>%
  mutate(count = n()) %>%
  filter(count > 200)
```


### Join water quality data to spatial data

```{r}
spatial_200 <- inner_join(spatial_lakes,chla_secchi_200 %>%
                            distinct(lagoslakeid,.keep_all=T),
                          by='lagoslakeid')
```

### Mean Chl_a map

```{r}
### Take the mean chl_a and secchi by lake

mean_values_200 <- chla_secchi_200 %>%
  # Take summary by lake id
  group_by(lagoslakeid) %>%
  # take mean chl_a per lake id
  summarize(mean_chl = mean(chla,na.rm=T),
            mean_secchi=mean(secchi,na.rm=T)) %>%
  #Get rid of NAs
  filter(!is.na(mean_chl),
         !is.na(mean_secchi)) %>%
  # Take the log base 10 of the mean_chl
  mutate(log10_mean_chl = log10(mean_chl))

#Join datasets
mean_spatial <- inner_join(spatial_lakes,mean_values_200,
                          by='lagoslakeid') 

#Make a map
mapview(mean_spatial,zcol='log10_mean_chl')
```


# Class work

## 1) What is the correlation between Secchi Disk Depth and Chlorophyll a for sites with at least 200 observations?

- Here, I just want a plot of chla vs secchi for all sites 

```{r}
ggplot(mean_values_200,aes(x = mean_chl, y = mean_secchi)) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x) +
  ggthemes::theme_few() +
  labs(x = "Mean Chlorophyll", y = "Mean Secchi Disk Depth", title = "Correlation between Secchi Disk Depth and Chlorophyll")
 
cor(mean_values_200$mean_chl,mean_values_200$mean_secchi)
```
For sites with over 200 observations, there is a slight negative correlation between secchi disk depth and chlorophyll content. The correlation value is `r cor(mean_values_200$mean_chl,mean_values_200$mean_secchi)` which is in agreement with the graph that shows a slight negative relationship between these values. As mean chlorophyll value increases, the mean secchi depth decreases. 

## Why might this be the case? 
Secchi disk depth measures the clarity of the water. A greater secchi value indicates higher clarity of the water. Chlorophyll is a pigment found in plants, algae, and phytoplankton, so this measurement can approximate algae content in water. A higher chlorophyll content suggests reduced clarity. A high chlorophyll content would therefore correspond to lower secchi disk readings.

## 2) What states have the most data? 

### 2a) First you will need to make a lagos spatial dataset that has the total number of counts per site.

```{r}
spatial_lakes <-lake_centers %>%
  group_by(lagoslakeid,nhd_long,nhd_lat) %>%
  count() %>%
  st_as_sf(.,coords=c('nhd_long','nhd_lat'),
                          crs=4326) 
```


### 2b) Second, you will need to join this point dataset to the us_boundaries data. 

```{r}
spatial_statelakes<- st_join(spatial_lakes,us_states())
```


### 2c) Then you will want to group by state and sum all the observations in that state and arrange that data from most to least total observations per state. 

```{r}
state_counts <- spatial_statelakes %>%
  as.data.frame() %>% # (remove geospatial data)
  select(-geometry) %>% #(removes geometry column)
  group_by(name) %>%
 summarize(statecount = sum(n)) %>%
 arrange(desc(statecount))
state_counts[1,1]
```

The state with the most data is `r state_counts[1,1]`.


## 3 Is there a spatial pattern in Secchi disk depth for lakes with at least 200 observations?

```{r}
secchi_200 <- clarity_only %>%
  group_by(lagoslakeid) %>%
  mutate(count = n()) %>%
  filter(count > 200) 
  
mean_secchi_200 <- secchi_200 %>%
  group_by(lagoslakeid) %>%
  summarize(mean_secchi=mean(secchi,na.rm=T)) %>%
  filter(!is.na(mean_secchi)) %>%
  mutate(log10_mean_secchi = log10(mean_secchi)) 
  
spatial_secchi_200 <- inner_join(spatial_lakes,mean_secchi_200 %>%
                            distinct(lagoslakeid,.keep_all=T),
                          by='lagoslakeid')
mapview(spatial_secchi_200, canvas = TRUE, zcol = 'mean_secchi', layer.name = 'Mean Secchi Depth')
```

There does seem to be a spatial pattern to the secchi disk depth. The New England states have higher secchi disk depth readings. Farther west, in states like Minnesota and Missouri, the secchi disk depth readings decrease. 
